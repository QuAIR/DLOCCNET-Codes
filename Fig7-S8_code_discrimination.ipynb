{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from quairkit import Circuit\n",
    "from quairkit.database import *\n",
    "from quairkit.qinfo import *\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import quairkit as qkit\n",
    "from quairkit import Circuit, to_state\n",
    "from quairkit.loss import *\n",
    "from quairkit.database.hamiltonian import ising_hamiltonian\n",
    "from quairkit.ansatz import *\n",
    "from quairkit.operator import ParamOracle\n",
    "import datetime\n",
    "\n",
    "qkit.set_dtype('complex128')\n",
    "\n",
    "def generate_single_pair(a):\n",
    "    rho_bell = bell_state(2).density_matrix\n",
    "    zero2 = torch.tensor([1, 0], dtype=torch.cdouble)\n",
    "    one2 = torch.tensor([0, 1], dtype=torch.cdouble)\n",
    "    basis00 = torch.kron(zero2, zero2)\n",
    "    basis11 = torch.kron(one2, one2)\n",
    "    psi_minus = (basis00 - basis11) / math.sqrt(2)\n",
    "    rho_minus = psi_minus.unsqueeze(1) @ psi_minus.conj().unsqueeze(0)\n",
    "\n",
    "    E0 = torch.tensor([[1, 0], [0, math.sqrt(1 - a)]], dtype=torch.cdouble)\n",
    "    E1 = torch.tensor([[0, math.sqrt(a)], [0, 0]], dtype=torch.cdouble)\n",
    "    K = [torch.kron(Ei, Ej) for Ei in (E0, E1) for Ej in (E0, E1)]\n",
    "    rho_damp = sum(Kij @ rho_minus @ Kij.conj().T for Kij in K)\n",
    "    \n",
    "    ## case of distinguishing the noisy phi^+ and the noisy phi^-, corresponding to Figure S9\n",
    "    # rho_damp_plus = sum(Kij @ rho_bell @ Kij.conj().T for Kij in K) \n",
    "    \n",
    "    rho_damp_plus = rho_bell # case of distinguishing  phi^+ and the noisy phi^-, corresponding to Figure 7\n",
    "\n",
    "    return rho_damp_plus, rho_damp\n",
    "\n",
    "def generate_initial_6qubit_states(a):\n",
    "    rho_bell, rho_damp = generate_single_pair(a)\n",
    "    state_bell = torch.kron(torch.kron(rho_bell, rho_bell), rho_bell)\n",
    "    state_damp = torch.kron(torch.kron(rho_damp, rho_damp), rho_damp)\n",
    "    batch = torch.stack([state_bell, state_damp])\n",
    "    inputs = to_state(batch, eps=None)\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "\n",
    "def prepare_new_pair_for_stage(outputs, a, stage_num):\n",
    "    rho_bell, rho_damp = generate_single_pair(a)\n",
    "    if hasattr(outputs, 'density_matrix'):\n",
    "        density_matrices = outputs.density_matrix\n",
    "    else:\n",
    "        density_matrices = outputs\n",
    "    batch_outputs = []\n",
    "    \n",
    "    for i in range(2):  \n",
    "        if hasattr(outputs[i], 'density_matrix'):\n",
    "            current_state = outputs[i].density_matrix\n",
    "        else:\n",
    "            current_state = density_matrices[i]\n",
    "        \n",
    "        state_obj = to_state(current_state, eps=None)\n",
    "        traced_state = partial_trace(state_obj, 1, [16, 4])\n",
    "        \n",
    "        if hasattr(traced_state, 'density_matrix'):\n",
    "            preserved_state = traced_state.density_matrix\n",
    "        else:\n",
    "            preserved_state = traced_state\n",
    "        \n",
    "        new_pair = rho_bell if i == 0 else rho_damp\n",
    "    \n",
    "        new_6qubit_state = torch.kron(preserved_state, new_pair)\n",
    "        \n",
    "        batch_outputs.append(new_6qubit_state)\n",
    "    \n",
    "    batch = torch.stack(batch_outputs)\n",
    "    \n",
    "    return to_state(batch, eps=None)\n",
    "\n",
    "def create_2copy_circuit():\n",
    "    cir = Circuit(6)\n",
    "    cir.swap([1,2])\n",
    "    cir.universal_two_qubits([0,1])\n",
    "    cir.param_locc(universal2, 15, [[0,1], 2, 3], label='M1', support_batch=False)\n",
    "    return cir\n",
    "\n",
    "def create_stage1_circuit():\n",
    "    cir = Circuit(6)\n",
    "    cir.swap([1,2])\n",
    "    cir.universal_two_qubits([0,1])\n",
    "    cir.param_locc(universal2, 15, [0, 2, 3], label='M1', support_batch=False)\n",
    "    return cir\n",
    "\n",
    "def create_stage2_circuit():\n",
    "    cir = Circuit(6)\n",
    "    cir.param_locc(universal2, 15, [2, 4, 1], label='M21', support_batch=False)\n",
    "    cir.param_locc(universal2, 15, [4, 5, 3], label='M22', support_batch=False)\n",
    "    cir.swap([0, 4])\n",
    "    cir.swap([2, 5])\n",
    "    return cir\n",
    "\n",
    "def create_middle_stage_circuit(stage_num):\n",
    "    cir = Circuit(6)\n",
    "    cir.param_locc(universal2, 15, [2, 4, 1], label=f'M{stage_num}1', support_batch=False)\n",
    "    cir.param_locc(universal2, 15, [4, 5, 3], label=f'M{stage_num}2', support_batch=False)\n",
    "    cir.swap([0, 4])\n",
    "    cir.swap([2, 5])\n",
    "    return cir\n",
    "\n",
    "def create_final_stage_circuit(stage_num):\n",
    "    cir = Circuit(6)\n",
    "    cir.param_locc(universal2, 15, [2, 4, 1], label=f'M{stage_num}1', support_batch=False)\n",
    "    cir.param_locc(universal2, 15, [[4,1], 5, 3], label=f'M{stage_num}2', support_batch=False)\n",
    "    cir.swap([0, 4])\n",
    "    cir.swap([2, 5])\n",
    "    return cir\n",
    "\n",
    "def create_all_circuits(n_copy):\n",
    "\n",
    "    n_stages = n_copy - 1\n",
    "    circuits = []\n",
    "    \n",
    "    if n_copy == 2:\n",
    "\n",
    "        circuits.append(create_2copy_circuit())\n",
    "    else:\n",
    "        circuits.append(create_stage1_circuit())\n",
    "        \n",
    "        if n_stages == 2:\n",
    "            circuits.append(create_final_stage_circuit(n_stages))\n",
    "        else:\n",
    "            circuits.append(create_stage2_circuit())\n",
    "            for stage in range(3, n_stages):\n",
    "                circuits.append(create_middle_stage_circuit(stage))\n",
    "            circuits.append(create_final_stage_circuit(n_stages))\n",
    "    \n",
    "    return circuits\n",
    "\n",
    "\n",
    "def loss_func_general(outputs, measure_qubits=[2, 3]):\n",
    "\n",
    "    meas = Measure('zz')\n",
    "    \n",
    "    probs_batch, outputsh = meas(outputs, qubits_idx=measure_qubits, keep_state=True)\n",
    "    prob_tensor = outputsh.probability\n",
    "    \n",
    "    shape = prob_tensor.shape\n",
    "    batch_size = shape[0]\n",
    "    num_branches = 1\n",
    "    for i in range(1, len(shape) - 1):\n",
    "        num_branches *= shape[i]\n",
    "    \n",
    "    prob_reshaped = prob_tensor.reshape(batch_size, num_branches, 4)\n",
    "    probs_cond_reshaped = probs_batch.reshape(batch_size, num_branches, 4)\n",
    "    branch_weights = prob_reshaped.sum(dim=2)\n",
    "    \n",
    "    marginalized_probs_list = []\n",
    "    for b in range(batch_size):\n",
    "        marginal_b = torch.zeros(4, dtype=torch.double)\n",
    "        for j in range(4):\n",
    "            weighted_sum = torch.sum(branch_weights[b] * probs_cond_reshaped[b, :, j])\n",
    "            marginal_b[j] = weighted_sum\n",
    "        marginalized_probs_list.append(marginal_b)\n",
    "    \n",
    "    marginalized_probs = torch.stack(marginalized_probs_list)\n",
    "    \n",
    "    normalized_probs_list = []\n",
    "    for b in range(batch_size):\n",
    "        norm_sum = marginalized_probs[b].sum()\n",
    "        normalized_prob = marginalized_probs[b] / norm_sum\n",
    "        normalized_probs_list.append(normalized_prob)\n",
    "\n",
    "    normalized_probs = torch.stack(normalized_probs_list)\n",
    "    \n",
    "    p0 = normalized_probs[0].real\n",
    "    p1 = normalized_probs[1].real\n",
    "    \n",
    "    F0_bell = p0[0] + p0[1]\n",
    "    T0_bell = p0[2] + p0[3]\n",
    "    eps = 1e-10\n",
    "    p0_prob = F0_bell / (F0_bell + T0_bell + eps)\n",
    "\n",
    "    F1_damped = p1[2] + p1[3]\n",
    "    T1_damped = p1[0] + p1[1]\n",
    "    p1_prob = F1_damped / (F1_damped + T1_damped + eps)\n",
    "    \n",
    "    loss = 0.5 * p0_prob + 0.5 * p1_prob\n",
    "    \n",
    "    return loss, outputs\n",
    "\n",
    "def loss_func_all_stages(circuits, inputs, a, n_copy):\n",
    "    n_stages = n_copy - 1\n",
    "    current_output = inputs\n",
    "    \n",
    "    if n_copy == 2:\n",
    "        # 2-copy\n",
    "        current_output = circuits[0](current_output)\n",
    "    else:\n",
    "        # >3-copy\n",
    "        # Stage 1\n",
    "        current_output = circuits[0](current_output)\n",
    "        \n",
    "        if n_stages == 2:\n",
    "            # Final Stage\n",
    "            current_output = circuits[1](current_output)\n",
    "        else:\n",
    "            # >= 4-copy\n",
    "            # Stage 2\n",
    "            current_output = circuits[1](current_output)\n",
    "            \n",
    "            # Stage 3 ro Stage N-1\n",
    "            for stage_idx in range(2, n_stages):\n",
    "                current_output = prepare_new_pair_for_stage(current_output, a, stage_idx + 1)\n",
    "                current_output = circuits[stage_idx](current_output)\n",
    "\n",
    "    loss, final_outputs = loss_func_general(current_output, measure_qubits=[2, 3])\n",
    "    \n",
    "    return loss, final_outputs\n",
    "\n",
    "def train_all_stages(num_itr, lr, a, n_copy, seed=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    inputs = generate_initial_6qubit_states(a)\n",
    "    \n",
    "    circuits = create_all_circuits(n_copy)\n",
    "    n_stages = len(circuits)\n",
    "    \n",
    "    optimizers = []\n",
    "    schedulers = []\n",
    "    for i, cir in enumerate(circuits):\n",
    "        opt = torch.optim.Adam(cir.parameters(), lr=lr)\n",
    "        optimizers.append(opt)\n",
    "        sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.98, patience=12)\n",
    "        schedulers.append(sched)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_states = None\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "    \n",
    "        loss, _ = loss_func_all_stages(circuits, inputs, a, n_copy)\n",
    "        loss.backward()\n",
    "\n",
    "        for opt in optimizers:\n",
    "            opt.step()\n",
    "        for sched in schedulers:\n",
    "            sched.step(loss)\n",
    "        \n",
    "        lv = loss.item()\n",
    "        if lv < best_loss:\n",
    "            best_loss = lv\n",
    "            best_states = {}\n",
    "            for i, cir in enumerate(circuits):\n",
    "                best_states[f'stage{i+1}'] = {k: v.cpu().clone() for k, v in cir.state_dict().items()}\n",
    "\n",
    "        if itr % 600 == 0 or itr == num_itr - 1:\n",
    "            print(f\"    iter {itr:4d}/{num_itr} | loss = {lv:.8f} | best_loss = {best_loss:.8f}\")\n",
    "    if best_states:\n",
    "        for i, cir in enumerate(circuits):\n",
    "            cir.load_state_dict(best_states[f'stage{i+1}'])\n",
    "    \n",
    "    return best_loss, circuits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    N_COPY = 4  # N-copy, >= 2 \n",
    "    NUM_ITR = 600\n",
    "    print(f\"\\n>>> Running {N_COPY}-copy version <<<\\n\")\n",
    "\n",
    "  # ==========================================\n",
    "    seed_nums_a00 = 1    \n",
    "    seed_nums_a01 = 10   \n",
    "    seed_nums_a02 = 10    \n",
    "    seed_nums_a03 = 10   \n",
    "    seed_nums_a04 = 10   \n",
    "    seed_nums_a05 = 10   \n",
    "    seed_nums_a06 = 10    \n",
    "    seed_nums_a07 = 10    \n",
    "    seed_nums_a08 = 10  \n",
    "    seed_nums_a09 = 10    \n",
    "    seed_nums_a10 = 10   \n",
    "\n",
    "    seed_nums_list = [seed_nums_a00, seed_nums_a01, seed_nums_a02, seed_nums_a03, seed_nums_a04, seed_nums_a05, seed_nums_a06, seed_nums_a07, seed_nums_a08, seed_nums_a09, seed_nums_a10]\n",
    "\n",
    "\n",
    "\n",
    "    seed_start_a00 = 10    \n",
    "    seed_start_a01 = 50  \n",
    "    seed_start_a02 = 100   \n",
    "    seed_start_a03 = 150   \n",
    "    seed_start_a04 = 200  \n",
    "    seed_start_a05 = 250  \n",
    "    seed_start_a06 = 300  \n",
    "    seed_start_a07 = 350  \n",
    "    seed_start_a08 = 400  \n",
    "    seed_start_a09 = 450 \n",
    "    seed_start_a10 = 500  \n",
    "    \n",
    "    seed_start_list = [seed_start_a00, seed_start_a01, seed_start_a02, seed_start_a03, seed_start_a04, seed_start_a05, seed_start_a06, seed_start_a07, seed_start_a08, seed_start_a09, seed_start_a10]\n",
    "\n",
    "\n",
    "\n",
    "    seed_interval_a00 = 50    \n",
    "    seed_interval_a01 = 50  \n",
    "    seed_interval_a02 = 50  \n",
    "    seed_interval_a03 = 50  \n",
    "    seed_interval_a04 = 50 \n",
    "    seed_interval_a05 = 50\n",
    "    seed_interval_a06 = 50  \n",
    "    seed_interval_a07 = 50   \n",
    "    seed_interval_a08 = 50 \n",
    "    seed_interval_a09 = 50   \n",
    "    seed_interval_a10 = 50 \n",
    "    \n",
    "    seed_interval_list = [seed_interval_a00, seed_interval_a01, seed_interval_a02, seed_interval_a03, seed_interval_a04, seed_interval_a05, seed_interval_a06, seed_interval_a07, seed_interval_a08, seed_interval_a09, seed_interval_a10]\n",
    "\n",
    "    # ==========================================\n",
    "    \n",
    "\n",
    "    START_POINT = 0\n",
    "\n",
    "    a_vals_full = np.linspace(0.0, 1.0, 11)\n",
    "    \n",
    "    a_vals = a_vals_full[START_POINT:]\n",
    "    results = []\n",
    "    best_seeds_used = []  \n",
    "    detailed_results = []  \n",
    "    \n",
    "    print(f\"Starting from a = {a_vals[0]:.1f} (START_POINT = {START_POINT})\")\n",
    "    print(f\"Will train for a values: {[f'{a:.1f}' for a in a_vals]}\")\n",
    "    \n",
    "  \n",
    "    lr_a00 = 0.15   # a=0.0\n",
    "    lr_a01 = 0.15   # a=0.1\n",
    "    lr_a02 = 0.15   # a=0.2\n",
    "    lr_a03 = 0.15   # a=0.3\n",
    "    lr_a04 = 0.15   # a=0.4\n",
    "    lr_a05 = 0.15   # a=0.5\n",
    "    lr_a06 = 0.15   # a=0.6\n",
    "    lr_a07 = 0.15   # a=0.7\n",
    "    lr_a08 = 0.15   # a=0.8\n",
    "    lr_a09 = 0.15   # a=0.9\n",
    "    lr_a10 = 0.15   # a=1.0\n",
    "    \n",
    "    lr_list = [lr_a00, lr_a01, lr_a02, lr_a03, lr_a04, lr_a05, lr_a06, lr_a07, lr_a08, lr_a09, lr_a10]\n",
    "\n",
    "    for idx, a in enumerate(a_vals):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing a = {a:.2f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        actual_idx = idx + START_POINT\n",
    "        \n",
    "        lr = lr_list[actual_idx]\n",
    "        num_seeds = seed_nums_list[actual_idx]\n",
    "        seed_start = seed_start_list[actual_idx]\n",
    "        seed_interval = seed_interval_list[actual_idx]\n",
    "        \n",
    "        best_loss_for_a = float('inf')\n",
    "        best_seed_for_a = None\n",
    "        best_sp_for_a = 0\n",
    "        seed_results = []\n",
    "        seed_list = []\n",
    "        \n",
    "        print(f\"Trying {num_seeds} seeds for a={a:.2f}, lr={lr}\")\n",
    "        print(f\"Seed range: {seed_start} to {seed_start + (num_seeds-1)*seed_interval} with interval {seed_interval}\")\n",
    "        \n",
    "        for seed_idx in range(num_seeds):\n",
    "            current_seed = seed_start + seed_idx * seed_interval\n",
    "            seed_list.append(current_seed)\n",
    "            \n",
    "            print(f\"\\n  Seed {seed_idx+1}/{num_seeds}: seed={current_seed}\")\n",
    "            \n",
    "            best_loss, _ = train_all_stages(NUM_ITR, lr, a, N_COPY, seed=current_seed)\n",
    "            \n",
    "            sp = 1 - best_loss\n",
    "            seed_results.append(sp)\n",
    "            \n",
    "            print(f\"  -> Result: success_prob={sp:.6f}, loss={best_loss:.6f}\")\n",
    "            \n",
    "            if best_loss < best_loss_for_a:\n",
    "                best_loss_for_a = best_loss\n",
    "                best_seed_for_a = current_seed\n",
    "                best_sp_for_a = sp\n",
    "        \n",
    "        results.append(best_sp_for_a)\n",
    "        best_seeds_used.append(best_seed_for_a)\n",
    "        detailed_results.append({\n",
    "            'a': a,\n",
    "            'best_sp': best_sp_for_a,\n",
    "            'best_seed': best_seed_for_a,\n",
    "            'all_seeds': seed_list.copy(),\n",
    "            'all_results': seed_results.copy(),\n",
    "            'lr': lr,\n",
    "            'num_seeds': num_seeds,\n",
    "            'seed_start': seed_start,\n",
    "            'seed_interval': seed_interval\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nBest result for a={a:.2f}:\")\n",
    "        print(f\"  Best seed: {best_seed_for_a}\")\n",
    "        print(f\"  Best success probability: {best_sp_for_a:.6f}\")\n",
    "        print(f\"  Best loss: {best_loss_for_a:.6f}\")\n",
    "        print(f\"  All results: {[f'{sp:.4f}' for sp in seed_results]}\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL RESULTS SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for idx, (a, sp, seed) in enumerate(zip(a_vals, results, best_seeds_used)):\n",
    "        print(f\"a={a:.2f} | success_prob={sp:.6f} | best_seed={seed}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(a_vals, results, marker='o')\n",
    "    plt.xlabel(r'$\\gamma$')\n",
    "    plt.ylabel('Success Probability (1 - loss)')\n",
    "    plt.title(f'Success Probability vs AD channel parameter $\\\\gamma$ ({N_COPY}-copy)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if START_POINT > 0:\n",
    "        filename = f\"results_{N_COPY}copy_6qubit_multiseed_from{START_POINT}_{timestamp}.txt\"\n",
    "        data_filename = f\"data_{N_COPY}copy_6qubit_multiseed_from{START_POINT}_{timestamp}.txt\"\n",
    "        detail_filename = f\"detailed_{N_COPY}copy_6qubit_multiseed_from{START_POINT}_{timestamp}.txt\"\n",
    "    else:\n",
    "        filename = f\"results_{N_COPY}copy_6qubit_multiseed_{timestamp}.txt\"\n",
    "        data_filename = f\"data_{N_COPY}copy_6qubit_multiseed_{timestamp}.txt\"\n",
    "        detail_filename = f\"detailed_{N_COPY}copy_6qubit_multiseed_{timestamp}.txt\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "\n",
    "        f.write(f\"{N_COPY}-copy 6-qubit state discrimination results (Multi-Seed)\\n\")\n",
    "        f.write(f\"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Number of iterations: {NUM_ITR}\\n\")\n",
    "        f.write(f\"Start point: {START_POINT} (starting from a={a_vals[0]:.1f})\\n\")\n",
    "        f.write(\"\\nSeed configuration for each point:\\n\")\n",
    "        for idx, a in enumerate(a_vals):\n",
    "            actual_idx = idx + START_POINT\n",
    "            f.write(f\"  a={a:.2f}: {seed_nums_list[actual_idx]} seeds, start={seed_start_list[actual_idx]}, interval={seed_interval_list[actual_idx]}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(\"a\\tSuccess Probability\\tBest Seed\\tLR\\tSeeds Tried\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        \n",
    "\n",
    "        for idx, (a, sp, best_seed) in enumerate(zip(a_vals, results, best_seeds_used)):\n",
    "            actual_idx = idx + START_POINT\n",
    "            f.write(f\"{a:.2f}\\t{sp:.6f}\\t{best_seed}\\t{lr_list[actual_idx]}\\t{seed_nums_list[actual_idx]}\\n\")\n",
    "        \n",
    "\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        f.write(f\"Average success probability: {np.mean(results):.6f}\\n\")\n",
    "        f.write(f\"Maximum success probability: {np.max(results):.6f} at a={a_vals[np.argmax(results)]:.2f}\\n\")\n",
    "        f.write(f\"Minimum success probability: {np.min(results):.6f} at a={a_vals[np.argmin(results)]:.2f}\\n\")\n",
    "        f.write(f\"Total seeds used: {sum([d['num_seeds'] for d in detailed_results])}\\n\")\n",
    "    \n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "    \n",
    "\n",
    "    with open(detail_filename, 'w') as f:\n",
    "        f.write(f\"{N_COPY}-copy 6-qubit State Discrimination Detailed Results\\n\")\n",
    "        f.write(f\"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        for detail in detailed_results:\n",
    "            f.write(f\"\\na = {detail['a']:.2f} (lr = {detail['lr']}, num_seeds = {detail['num_seeds']}):\\n\")\n",
    "            f.write(f\"  Seed configuration: start={detail['seed_start']}, interval={detail['seed_interval']}\\n\")\n",
    "            f.write(f\"  Best result: {detail['best_sp']:.6f} (seed {detail['best_seed']})\\n\")\n",
    "            f.write(f\"  All seeds: {detail['all_seeds']}\\n\")\n",
    "            f.write(f\"  All results: {[f'{sp:.6f}' for sp in detail['all_results']]}\\n\")\n",
    "            if len(detail['all_results']) > 1:\n",
    "                f.write(f\"  Improvement over worst: {detail['best_sp'] - min(detail['all_results']):.6f}\\n\")\n",
    "                f.write(f\"  Standard deviation: {np.std(detail['all_results']):.6f}\\n\")\n",
    "    \n",
    "    print(f\"Detailed results saved to {detail_filename}\")\n",
    "    \n",
    "    np.savetxt(data_filename, np.column_stack([a_vals, results, best_seeds_used]), \n",
    "               delimiter='\\t', header='a\\tsuccess_probability\\tbest_seed', comments='')\n",
    "    print(f\"Data saved to {data_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devquair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
