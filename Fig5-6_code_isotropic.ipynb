{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotropic state distillation - multi copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import quairkit as qkit\n",
    "from quairkit import Circuit\n",
    "from quairkit import to_state\n",
    "from quairkit.database import *\n",
    "from quairkit.loss import *\n",
    "from quairkit.qinfo import *\n",
    "from quairkit.database.hamiltonian import ising_hamiltonian\n",
    "from quairkit.ansatz import *\n",
    "from quairkit.operator import ParamOracle\n",
    "\n",
    "qkit.set_dtype('complex128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic LOCCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynloccnetcir(n):\n",
    "    cir = Circuit(2*n)\n",
    "    cir.universal_qudits(qubits_idx=[0,2,4,6])\n",
    "    cir.universal_qudits(qubits_idx=[1,3,5,7])\n",
    "\n",
    "    return cir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_5(cir1, cir2, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state2 = measure_state2(state2, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state2,0,[2**6,4]).density_matrix\n",
    "\n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_5(num_itr, LR, n, target_state,noisy_state2):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "       \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5) \n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5) \n",
    "       \n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "\n",
    "        loss, output_state3,_ = loss_func_dyn_5(cir1,cir2, target_state, noisy_state2) \n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        scheduler1.step(loss) \n",
    "        scheduler2.step(loss)\n",
    " \n",
    "            \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_6(cir1, cir2, cir3, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state2)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state3 = measure_state2(state3, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state3,0,[2**6,4]).density_matrix\n",
    "\n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_6(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5) \n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5) \n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5) \n",
    "\n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    " \n",
    "        loss, output_state3,_ = loss_func_dyn_6(cir1, cir2, cir3, target_state, noisy_state)\n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "\n",
    "        scheduler1.step(loss) \n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_7(cir1, cir2, cir3, cir4, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state2)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    _, m_state3 = measure_state(state3, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state3 = partial_trace(m_state3,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state4 = torch.kron(output_state3,noisy_state2)\n",
    "    state4 = cir4(to_state(input_state4,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state4 = measure_state2(state4, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state4,0,[2**6,4]).density_matrix\n",
    " \n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_7(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    cir4 = dynloccnetcir(n)\n",
    "\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters())\n",
    "    opt_cir4 = torch.optim.Adam(lr=LR, params=cir4.parameters()) \n",
    "\n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5)\n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5)\n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5) \n",
    "    scheduler4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir4, 'min', factor=0.5) \n",
    "  \n",
    "    \n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    "        opt_cir4.zero_grad()\n",
    "        \n",
    "        loss, output_state3,_ = loss_func_dyn_7(cir1, cir2, cir3, cir4, target_state, noisy_state) \n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "        opt_cir4.step()\n",
    "        scheduler1.step(loss)\n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        scheduler4.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_8(cir1, cir2, cir3, cir4, cir5, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state2)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    _, m_state3 = measure_state(state3, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state3 = partial_trace(m_state3,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state4 = torch.kron(output_state3,noisy_state2)\n",
    "    state4 = cir4(to_state(input_state4,eps=None))\n",
    "    _, m_state4 = measure_state(state4, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state4 = partial_trace(m_state4,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state5 = torch.kron(output_state4,noisy_state2)\n",
    "    state5 = cir5(to_state(input_state5,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state5 = measure_state2(state5, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state5,0,[2**6,4]).density_matrix\n",
    " \n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_8(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    cir4 = dynloccnetcir(n)\n",
    "    cir5 = dynloccnetcir(n)\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5)\n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5) \n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters()) \n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5) \n",
    "    opt_cir4 = torch.optim.Adam(lr=LR, params=cir4.parameters()) \n",
    "    scheduler4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir4, 'min', factor=0.5)\n",
    "    opt_cir5 = torch.optim.Adam(lr=LR, params=cir5.parameters()) \n",
    "    scheduler5 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir5, 'min', factor=0.5) \n",
    "\n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    "        opt_cir4.zero_grad()\n",
    "        opt_cir5.zero_grad()\n",
    "        \n",
    "        loss, output_state3,_ = loss_func_dyn_8(cir1, cir2, cir3, cir4, cir5, target_state, noisy_state)\n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "        opt_cir4.step()\n",
    "        opt_cir5.step()\n",
    "\n",
    "        scheduler1.step(loss) \n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        scheduler4.step(loss)\n",
    "        scheduler5.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_9(cir1, cir2, cir3, cir4, cir5, cir6, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state2)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    _, m_state3 = measure_state(state3, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state3 = partial_trace(m_state3,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state4 = torch.kron(output_state3,noisy_state2)\n",
    "    state4 = cir4(to_state(input_state4,eps=None))\n",
    "    _, m_state4 = measure_state(state4, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state4 = partial_trace(m_state4,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state5 = torch.kron(output_state4,noisy_state2)\n",
    "    state5 = cir5(to_state(input_state5,eps=None))\n",
    "    _, m_state5 = measure_state(state5, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state5 = partial_trace(m_state5,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state6 = torch.kron(output_state5,noisy_state2)\n",
    "    state6 = cir6(to_state(input_state6,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state6 = measure_state2(state6, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state6,0,[2**6,4]).density_matrix\n",
    " \n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_9(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    cir4 = dynloccnetcir(n)\n",
    "    cir5 = dynloccnetcir(n)\n",
    "    cir6 = dynloccnetcir(n)\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5)\n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5)\n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters()) \n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5)\n",
    "    opt_cir4 = torch.optim.Adam(lr=LR, params=cir4.parameters()) \n",
    "    scheduler4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir4, 'min', factor=0.5) \n",
    "    opt_cir5 = torch.optim.Adam(lr=LR, params=cir5.parameters()) \n",
    "    scheduler5 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir5, 'min', factor=0.5) \n",
    "    opt_cir6 = torch.optim.Adam(lr=LR, params=cir6.parameters()) \n",
    "    scheduler6 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir6, 'min', factor=0.5) \n",
    "    \n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    "        opt_cir4.zero_grad()\n",
    "        opt_cir5.zero_grad()\n",
    "        opt_cir6.zero_grad()\n",
    "        \n",
    "        loss, output_state3,_ = loss_func_dyn_9(cir1, cir2, cir3, cir4, cir5, cir6, target_state, noisy_state) \n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "        opt_cir4.step()\n",
    "        opt_cir5.step()\n",
    "        opt_cir6.step()\n",
    "\n",
    "        scheduler1.step(loss)\n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        scheduler4.step(loss)\n",
    "        scheduler5.step(loss)\n",
    "        scheduler6.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_dyn_10(cir1, cir2, cir3, cir4, cir5, cir6, cir7, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = torch.kron(torch.kron(torch.kron(noisy_state2,noisy_state2),noisy_state2),noisy_state2)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state2 = torch.kron(output_state1,noisy_state2)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state2)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    _, m_state3 = measure_state(state3, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state3 = partial_trace(m_state3,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state4 = torch.kron(output_state3,noisy_state2)\n",
    "    state4 = cir4(to_state(input_state4,eps=None))\n",
    "    _, m_state4 = measure_state(state4, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state4 = partial_trace(m_state4,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state5 = torch.kron(output_state4,noisy_state2)\n",
    "    state5 = cir5(to_state(input_state5,eps=None))\n",
    "    _, m_state5 = measure_state(state5, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state5 = partial_trace(m_state5,0,[4,2**6]).density_matrix\n",
    "    \n",
    "    input_state6 = torch.kron(output_state5,noisy_state2)\n",
    "    state6 = cir6(to_state(input_state6,eps=None))\n",
    "    _, m_state6 = measure_state(state6, qubits_idx=list(range(2)),keep_state=True,desired_result='0'*2)\n",
    "    output_state6 = partial_trace(m_state6,0,[4,2**6]).density_matrix\n",
    "        \n",
    "    input_state7 = torch.kron(output_state6,noisy_state2)\n",
    "    state7 = cir7(to_state(input_state7,eps=None))\n",
    "    measure_state2 = Measure('z'* 6)\n",
    "    _, m_state7 = measure_state2(state7, qubits_idx=list(range(6)),keep_state=True,desired_result='0'*6)\n",
    "    output_state = partial_trace(m_state7,0,[2**6,4]).density_matrix\n",
    " \n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn_10(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    cir4 = dynloccnetcir(n)\n",
    "    cir5 = dynloccnetcir(n)\n",
    "    cir6 = dynloccnetcir(n)\n",
    "    cir7 = dynloccnetcir(n)\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5) \n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) \n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5) \n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters())\n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5)\n",
    "    opt_cir4 = torch.optim.Adam(lr=LR, params=cir4.parameters()) \n",
    "    scheduler4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir4, 'min', factor=0.5) \n",
    "    opt_cir5 = torch.optim.Adam(lr=LR, params=cir5.parameters()) \n",
    "    scheduler5 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir5, 'min', factor=0.5) \n",
    "    opt_cir6 = torch.optim.Adam(lr=LR, params=cir6.parameters()) \n",
    "    scheduler6 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir6, 'min', factor=0.5) \n",
    "    opt_cir7 = torch.optim.Adam(lr=LR, params=cir7.parameters()) \n",
    "    scheduler7 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir7, 'min', factor=0.5) \n",
    "\n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    "        opt_cir4.zero_grad()\n",
    "        opt_cir5.zero_grad()\n",
    "        opt_cir6.zero_grad()\n",
    "        opt_cir7.zero_grad()\n",
    "        \n",
    "        loss, output_state3,_ = loss_func_dyn_10(cir1, cir2, cir3, cir4, cir5, cir6, cir7, target_state, noisy_state) \n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "        opt_cir4.step()\n",
    "        opt_cir5.step()\n",
    "        opt_cir6.step()\n",
    "        opt_cir7.step()\n",
    "\n",
    "        scheduler1.step(loss) \n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        scheduler4.step(loss)\n",
    "        scheduler5.step(loss)\n",
    "        scheduler6.step(loss)\n",
    "        scheduler7.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOCCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loccnetcir(m):\n",
    "        \n",
    "    A_list = []\n",
    "    B_list = []\n",
    "    for i in range(m):\n",
    "        a = 2 * i\n",
    "        b = 2 * i + 1\n",
    "        A_list.append(a)\n",
    "        B_list.append(b)\n",
    "        \n",
    "    cir = Circuit(2*m)\n",
    "    cir.universal_qudits(qubits_idx=A_list)\n",
    "    cir.universal_qudits(qubits_idx=B_list)\n",
    "    \n",
    "    return cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func_loccnet(cir1, m, target_state, noisy_state2):\n",
    "    \n",
    "    input_state1 = nkron(*[noisy_state2 for _ in range(m)])\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* (2*m-2))\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2*m-2)),keep_state=True,desired_result='0'*(2*m-2))\n",
    "    output_state = partial_trace(m_state,0,[2**(2*m-2),2**2]).density_matrix\n",
    "\n",
    "    loss = 1 - state_fidelity(target_state,output_state)**2\n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_loccnet(num_itr, LR, m, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    cir1 = loccnetcir(m)\n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) \n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5) \n",
    "\n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        loss, output_state3,_ = loss_func_loccnet(cir1, m, target_state, noisy_state) \n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "\n",
    "        scheduler1.step(loss) \n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # qubits number of dloccnet per round\n",
    "m = 4 # qubit number of loccnet\n",
    "NUM_ITR = 2000 # iteration\n",
    "LR = 0.1 # learning rate\n",
    "target_state = bell_state(2).density_matrix # target state\n",
    "\n",
    "fid_dynamic = []\n",
    "fid_loccnet = []\n",
    "fid_iso1 = []\n",
    "\n",
    "p1 = 8 # 10 times of noise parameter \n",
    "iso_state = (p1/10) * bell_state(2).density_matrix + (1-p1/10) * eye(4)/4\n",
    "fid1 = state_fidelity(iso_state,target_state).item()**2\n",
    "fid_iso1.append(fid1)\n",
    "\n",
    "## 4 copies of isotropic state, dloccnet is equal to loccnet in this case\n",
    "# f4 = train_model_loccnet(NUM_ITR, LR, 4, target_state,iso_state)\n",
    "# fid_dynamic.append(f4)\n",
    "# fid_loccnet.append(f4)\n",
    "\n",
    "## dloccnet\n",
    "### 5 copies of isotropic\n",
    "# fdyn5 = train_model_dyn_5(NUM_ITR, LR, n, target_state,iso_state)\n",
    "# fid_dynamic.append(fdyn5)\n",
    "### 6 copies of isotropic\n",
    "# fdyn6 = train_model_dyn_6(NUM_ITR, LR, n, target_state,iso_state)\n",
    "# fid_dynamic.append(fdyn6)\n",
    "### 7 copies of isotropic\n",
    "# fdyn7 = train_model_dyn_7(NUM_ITR, LR, n, target_state,iso_state)\n",
    "# fid_dynamic.append(fdyn7)\n",
    "### 8 copies of isotropic\n",
    "# fdyn8 = train_model_dyn_8(NUM_ITR, LR, n, target_state,iso_state)\n",
    "# fid_dynamic.append(fdyn8)\n",
    "### 9 copies of isotropic\n",
    "# fdyn9 = train_model_dyn_9(NUM_ITR, LR, n, target_state,iso_state)\n",
    "# fid_dynamic.append(fdyn9)\n",
    "### 10 copies of isotropic\n",
    "fdyn10 = train_model_dyn_10(NUM_ITR, LR, n, target_state,iso_state)\n",
    "fid_dynamic.append(fdyn10)\n",
    "\n",
    "## dloccnet\n",
    "### 5 copies of isotropic\n",
    "# f5 = train_model_loccnet(NUM_ITR, LR, m, target_state,iso_state)\n",
    "# fid_loccnet.append(f5)\n",
    "### 6 copies of isotropic\n",
    "f6 = train_model_loccnet(NUM_ITR, LR, m, target_state,iso_state)\n",
    "fid_loccnet.append(f6)\n",
    "\n",
    "print('10-copy of dyamic 4-3',fid_dynamic)\n",
    "print('loccnet',fid_loccnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devquair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
