{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic method comparison for state distillation - 5 copies of S state \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import quairkit as qkit\n",
    "from quairkit import Circuit\n",
    "from quairkit import to_state\n",
    "from quairkit.database import *\n",
    "from quairkit.loss import *\n",
    "from quairkit.qinfo import *\n",
    "from quairkit.database.hamiltonian import ising_hamiltonian\n",
    "from quairkit.ansatz import *\n",
    "from quairkit.operator import ParamOracle\n",
    "\n",
    "qkit.set_dtype('complex128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal DLOCCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynloccnetcir(n):\n",
    "    cir = Circuit(2*n)\n",
    "    cir.universal_qudits(qubits_idx=[0,2])\n",
    "    cir.universal_qudits(qubits_idx=[1,3])\n",
    "\n",
    "    \n",
    "    return cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func4(cir1, cir2, cir3, cir4, target_state, noisy_state):\n",
    "    \n",
    "    input_state1 = torch.kron(noisy_state,noisy_state)\n",
    "    state1 = cir1(to_state(input_state1,eps=None))\n",
    "    measure_state = Measure('z'* 2)\n",
    "    _, m_state = measure_state(state1, qubits_idx=list(range(2,4)),keep_state=True,desired_result='0'*2)\n",
    "    output_state1 = partial_trace(m_state,1,[4,4]).density_matrix\n",
    "    \n",
    "    input_state2 = torch.kron(output_state1,noisy_state)\n",
    "    state2 = cir2(to_state(input_state2,eps=None))\n",
    "    _, m_state2 = measure_state(state2, qubits_idx=list(range(2,4)),keep_state=True,desired_result='0'*2)\n",
    "    output_state2 = partial_trace(m_state2,1,[4,4]).density_matrix\n",
    "    \n",
    "    input_state3 = torch.kron(output_state2,noisy_state)\n",
    "    state3 = cir3(to_state(input_state3,eps=None))\n",
    "    _, m_state3 = measure_state(state3, qubits_idx=list(range(2,4)),keep_state=True,desired_result='0'*2)\n",
    "    output_state3 = partial_trace(m_state3,1,[4,4]).density_matrix\n",
    "    \n",
    "    input_state4 = torch.kron(output_state3,noisy_state)\n",
    "    state4 = cir4(to_state(input_state4,eps=None))\n",
    "    _, m_state4 = measure_state(state4, qubits_idx=list(range(2,4)),keep_state=True,desired_result='0'*2)\n",
    "    output_state = partial_trace(m_state4,1,[4,4]).density_matrix\n",
    " \n",
    "    f = state_fidelity(target_state,output_state).item()**2\n",
    "    loss = 1-state_fidelity(target_state,output_state)**2\n",
    "    \n",
    "    return loss, output_state,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_dyn4(num_itr, LR, n, target_state,noisy_state):\n",
    "    \n",
    "    loss_list, time_list = [], []\n",
    "    \n",
    "    cir1 = dynloccnetcir(n)\n",
    "    cir2 = dynloccnetcir(n)\n",
    "    cir3 = dynloccnetcir(n)\n",
    "    cir4 = dynloccnetcir(n)\n",
    "    \n",
    "    opt_cir1 = torch.optim.Adam(lr=LR, params=cir1.parameters()) # cir is a Circuit type\n",
    "    opt_cir2 = torch.optim.Adam(lr=LR, params=cir2.parameters()) # cir is a Circuit type\n",
    "    opt_cir3 = torch.optim.Adam(lr=LR, params=cir3.parameters()) # cir is a Circuit type\n",
    "    opt_cir4 = torch.optim.Adam(lr=LR, params=cir4.parameters()) # cir is a Circuit type\n",
    "    scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir1, 'min', factor=0.5) # activate scheduler\n",
    "    scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir2, 'min', factor=0.5) # activate scheduler\n",
    "    scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir3, 'min', factor=0.5) # activate scheduler\n",
    "    scheduler4 = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_cir4, 'min', factor=0.5) # activate scheduler\n",
    "    print('Training:')\n",
    "    \n",
    "    for itr in range(num_itr):\n",
    "        start_time = time.time()\n",
    "        opt_cir1.zero_grad()\n",
    "        opt_cir2.zero_grad()\n",
    "        opt_cir3.zero_grad()\n",
    "        opt_cir4.zero_grad()\n",
    "        \n",
    "        loss, output_state3,_ = loss_func4(cir1, cir2, cir3, cir4, target_state, noisy_state) # compute loss\n",
    "        loss.backward()\n",
    "        opt_cir1.step()\n",
    "        opt_cir2.step()\n",
    "        opt_cir3.step()\n",
    "        opt_cir4.step()\n",
    "        scheduler1.step(loss) # activate scheduler\n",
    "        scheduler2.step(loss)\n",
    "        scheduler3.step(loss)\n",
    "        scheduler4.step(loss)\n",
    "        \n",
    "        loss = loss.item()\n",
    "        loss_list.append(loss)\n",
    "        time_list.append(time.time() - start_time)\n",
    "        \n",
    "        if itr % 500 == 0 or itr == num_itr - 1:\n",
    "            print(\n",
    "                f\"iter: {itr}, loss: {loss:.8f}, lr: {scheduler1.get_last_lr()[0]:.2E}, avg_time: {np.mean(time_list):.4f}s\"\n",
    "            )\n",
    "            time_list = []\n",
    "\n",
    "    output_state = output_state3.detach()\n",
    "    fid = state_fidelity(output_state,target_state).item()**2\n",
    "    \n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEJMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dejmps(n):\n",
    "    cir = Circuit(2*n)\n",
    "    cir.rx(param=np.pi/2,qubits_idx=[0,2]) \n",
    "    cir.rx(param=-np.pi/2,qubits_idx=[1,3])\n",
    "    for i in range(2):\n",
    "        cir.cnot([i,i+2])\n",
    "    \n",
    "    return cir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simcir1(n,p):\n",
    "    cir = Circuit(2*n)\n",
    "\n",
    "    cir.cnot([2,0])\n",
    "    cir.cnot([3,1])\n",
    "    cir.cnot([1,3])\n",
    "    cir.ry(param=np.arccos(1-p)+np.pi,qubits_idx=[2,3]) \n",
    "    \n",
    "    return cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simcir2(n):\n",
    "    cir = Circuit(2*n)\n",
    "\n",
    "    cir.cnot([2,0])\n",
    "    cir.cnot([3,1])\n",
    "    cir.ry(param=-np.pi/2,qubits_idx=[2,3]) \n",
    "    \n",
    "    return cir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "iter: 0, loss: 0.95730093, lr: 1.00E-01, avg_time: 0.0079s\n",
      "iter: 500, loss: 0.13909109, lr: 2.50E-02, avg_time: 0.0049s\n",
      "iter: 1000, loss: 0.04230156, lr: 3.13E-03, avg_time: 0.0047s\n",
      "iter: 1499, loss: 0.04230014, lr: 1.19E-08, avg_time: 0.0046s\n",
      "dynamic [0.9576998511712534]\n",
      "simplify [0.9746251484448544]\n",
      "dejmps [0.9224533512234494]\n",
      "no distillation [0.6500000004837357]\n",
      "Training:\n",
      "iter: 0, loss: 0.91947402, lr: 1.00E-01, avg_time: 0.0047s\n",
      "iter: 500, loss: 0.01752289, lr: 5.00E-02, avg_time: 0.0045s\n",
      "iter: 1000, loss: 0.01219715, lr: 1.25E-02, avg_time: 0.0045s\n",
      "iter: 1499, loss: 0.00849160, lr: 6.25E-03, avg_time: 0.0046s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272]\n",
      "simplify [0.9746251484448544, 0.9913294803661782]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352]\n",
      "Training:\n",
      "iter: 0, loss: 0.85885657, lr: 1.00E-01, avg_time: 0.0046s\n",
      "iter: 500, loss: 0.01664705, lr: 2.50E-02, avg_time: 0.0048s\n",
      "iter: 1000, loss: 0.00542861, lr: 2.50E-02, avg_time: 0.0045s\n",
      "iter: 1499, loss: 0.00519424, lr: 3.13E-03, avg_time: 0.0045s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007]\n",
      "Training:\n",
      "iter: 0, loss: 0.86465463, lr: 1.00E-01, avg_time: 0.0047s\n",
      "iter: 500, loss: 0.00590940, lr: 2.50E-02, avg_time: 0.0045s\n",
      "iter: 1000, loss: 0.00128880, lr: 2.50E-02, avg_time: 0.0045s\n",
      "iter: 1499, loss: 0.00099807, lr: 2.50E-02, avg_time: 0.0045s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034, 0.9990019299286002]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321, 0.9993198266355168]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037, 0.9961089708552243]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007, 0.8000000088172974]\n",
      "Training:\n",
      "iter: 0, loss: 0.65689576, lr: 1.00E-01, avg_time: 0.0046s\n",
      "iter: 500, loss: 0.00436396, lr: 3.81E-07, avg_time: 0.0044s\n",
      "iter: 1000, loss: 0.00436394, lr: 1.19E-08, avg_time: 0.0044s\n",
      "iter: 1499, loss: 0.00436394, lr: 1.19E-08, avg_time: 0.0045s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034, 0.9990019299286002, 0.9956360642337865]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321, 0.9993198266355168, 0.9998704673810227]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037, 0.9961089708552243, 0.9990311362400123]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007, 0.8000000088172974, 0.8500000142615143]\n",
      "Training:\n",
      "iter: 0, loss: 0.90749877, lr: 1.00E-01, avg_time: 0.0046s\n",
      "iter: 500, loss: 0.00154117, lr: 5.00E-02, avg_time: 0.0045s\n",
      "iter: 1000, loss: 0.00075930, lr: 1.19E-08, avg_time: 0.0044s\n",
      "iter: 1499, loss: 0.00075930, lr: 1.19E-08, avg_time: 0.0045s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034, 0.9990019299286002, 0.9956360642337865, 0.9992407297655951]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321, 0.9993198266355168, 0.9998704673810227, 0.9999860123063491]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037, 0.9961089708552243, 0.9990311362400123, 0.9998476260918697]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007, 0.8000000088172974, 0.8500000142615143, 0.9000000125920428]\n",
      "Training:\n",
      "iter: 0, loss: 0.84578669, lr: 1.00E-01, avg_time: 0.0046s\n",
      "iter: 500, loss: 0.00106268, lr: 2.38E-08, avg_time: 0.0057s\n",
      "iter: 1000, loss: 0.00106267, lr: 1.19E-08, avg_time: 0.0049s\n",
      "iter: 1499, loss: 0.00106268, lr: 1.19E-08, avg_time: 0.0055s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034, 0.9990019299286002, 0.9956360642337865, 0.9992407297655951, 0.9989373345351641]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321, 0.9993198266355168, 0.9998704673810227, 0.9999860123063491, 0.9999996342816205]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037, 0.9961089708552243, 0.9990311362400123, 0.9998476260918697, 0.9999923347242738]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007, 0.8000000088172974, 0.8500000142615143, 0.9000000125920428, 0.9500000149888743]\n",
      "Training:\n",
      "iter: 0, loss: 0.83725237, lr: 1.00E-01, avg_time: 0.0047s\n",
      "iter: 500, loss: -0.00000000, lr: 1.19E-08, avg_time: 0.0047s\n",
      "iter: 1000, loss: -0.00000000, lr: 1.19E-08, avg_time: 0.0054s\n",
      "iter: 1499, loss: -0.00000002, lr: 1.19E-08, avg_time: 0.0045s\n",
      "dynamic [0.9576998511712534, 0.9915084087841272, 0.9948057570645034, 0.9990019299286002, 0.9956360642337865, 0.9992407297655951, 0.9989373345351641, 1.000000026290005]\n",
      "simplify [0.9746251484448544, 0.9913294803661782, 0.997347913250321, 0.9993198266355168, 0.9998704673810227, 0.9999860123063491, 0.9999996342816205, 1.0000000005999987]\n",
      "dejmps [0.9224533512234494, 0.9673650359393162, 0.9878048935841037, 0.9961089708552243, 0.9990311362400123, 0.9998476260918697, 0.9999923347242738, 1.0000000005999987]\n",
      "no distillation [0.6500000004837357, 0.7000000064444352, 0.7500000131505007, 0.8000000088172974, 0.8500000142615143, 0.9000000125920428, 0.9500000149888743, 1.0000000005999983]\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "NUM_ITR = 1500\n",
    "LR = 0.1\n",
    "target_state = bell_state(2).density_matrix\n",
    "\n",
    "fid_s = []\n",
    "\n",
    "fid_dynamic = []\n",
    "fid_de = []\n",
    "fid_iso1 = []\n",
    "fid_sim = []\n",
    "\n",
    "cir_de1 = dejmps(n)\n",
    "\n",
    "cir_sim2 = simcir2(n)\n",
    "cir_sim3 = simcir2(n)\n",
    "cir_sim4 = simcir2(n)\n",
    "\n",
    "for p1 in range(3,11):\n",
    "    s1 = (p1/10) * bell_state(2).density_matrix + (1-p1/10) * zero_state(2).density_matrix\n",
    "    fid1 = state_fidelity(s1,target_state).item()**2\n",
    "    fid_s.append(fid1)\n",
    "\n",
    "    # dynamic universal DLOCCNet\n",
    "    fdyn4 = train_model_dyn4(NUM_ITR, LR, n, target_state, s1)\n",
    "    fid_dynamic.append(fdyn4)\n",
    "\n",
    "    # our protocol\n",
    "    cir_sim1 = simcir1(n,p1/10)\n",
    "    _, _, fsim4 = loss_func4(cir_sim1, cir_sim2, cir_sim3,cir_sim4, target_state, s1)\n",
    "    # fsim4 = train_model_sim4(NUM_ITR, LR, n, target_state, s1)\n",
    "    fid_sim.append(fsim4)\n",
    "\n",
    "    # dynamic DEJPMS\n",
    "    _, _, fde4 = loss_func4(cir_de1, cir_de1, cir_de1, cir_de1, target_state, s1)\n",
    "    fid_de.append(fde4)\n",
    "\n",
    "    print('dynamic universal dloccnet',fid_dynamic)\n",
    "    print('our protocol',fid_sim)\n",
    "    print('dynamic dejmps',fid_de)\n",
    "    print('no distillation',fid_s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devquair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
